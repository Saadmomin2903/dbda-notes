# Machine Learning - Visual Cheat Sheet

**One-Page Quick Reference for PG-DBDA ML Exam**

---

## ğŸ¯ Algorithm Selection Flowchart

```
START: What is your task?
â”‚
â”œâ”€ SUPERVISED LEARNING (Have labeled data)
â”‚  â”‚
â”‚  â”œâ”€ REGRESSION (Predict continuous value)
â”‚  â”‚  â”œâ”€ Linear relationships â†’ Linear Regression
â”‚  â”‚  â”œâ”€ Non-linear â†’ Polynomial Regression
â”‚  â”‚  â”œâ”€ Prevent overfitting â†’ Ridge/Lasso
â”‚  â”‚  â”œâ”€ Many features â†’ ElasticNet
â”‚  â”‚  â”œâ”€ Non-linear complex â†’ Decision Tree / Random Forest / Gradient Boosting
â”‚  â”‚  â””â”€ Sequential data â†’ LSTM / GRU
â”‚  â”‚
â”‚  â””â”€ CLASSIFICATION (Predict category)
â”‚     â”œâ”€ Linear separable â†’ Logistic Regression / SVM (linear)
â”‚     â”œâ”€ Non-linear â†’ SVM (RBF kernel)
â”‚     â”œâ”€ Probabilistic â†’ Naive Bayes
â”‚     â”œâ”€ Interpretable â†’ Decision Tree
â”‚     â”œâ”€ High accuracy â†’ Random Forest / Gradient Boosting / XGBoost
â”‚     â”œâ”€ Distance-based â†’ k-NN (but slow!)
â”‚     â”œâ”€ Text data â†’ Naive Bayes / Logistic Regression / BERT
â”‚     â”œâ”€ Image data â†’ CNN / ResNet / Vision Transformer
â”‚     â””â”€ Sequential â†’ RNN / LSTM / Transformer
â”‚
â”œâ”€ UNSUPERVISED LEARNING (No labels)
â”‚  â”‚
â”‚  â”œâ”€ CLUSTERING (Group similar data)
â”‚  â”‚  â”œâ”€ Know # clusters â†’ k-Means
â”‚  â”‚  â”œâ”€ Unknown # clusters â†’ DBSCAN / Hierarchical
â”‚  â”‚  â”œâ”€ Soft clusters â†’ Gaussian Mixture Models
â”‚  â”‚  â””â”€ High-dimensional â†’ Spectral Clustering
â”‚  â”‚
â”‚  â”œâ”€ DIMENSIONALITY REDUCTION
â”‚  â”‚  â”œâ”€ Linear â†’ PCA
â”‚  â”‚  â”œâ”€ Non-linear â†’ t-SNE / UMAP
â”‚  â”‚  â”œâ”€ Preserve variance â†’ PCA
â”‚  â”‚  â”œâ”€ Visualization â†’ t-SNE (2D/3D)
â”‚  â”‚  â””â”€ With labels available â†’ LDA
â”‚  â”‚
â”‚  â””â”€ ANOMALY DETECTION
â”‚     â”œâ”€ Isolation Forest
â”‚     â”œâ”€ One-Class SVM
â”‚     â””â”€ Autoencoder
â”‚
â””â”€ REINFORCEMENT LEARNING (Learn from environment)
   â”œâ”€ Q-Learning (discrete actions)
   â”œâ”€ DQN (deep Q-network)
   â”œâ”€ Policy Gradient (continuous actions)
   â””â”€ Actor-Critic / PPO
```

---

## ğŸ“Š Model Comparison Matrix

| Model | Type | Pros | Cons | When to Use |
|-------|------|------|------|-------------|
| **Linear Regression** | Regression | Fast, interpretable | Assumes linearity | Linear relationships |
| **Logistic Regression** | Classification | Fast, probabilistic | Linear decision boundary | Baseline classifier |
| **Decision Tree** | Both | Interpretable, no scaling | Overfits, unstable | Need interpretability |
| **Random Forest** | Both | High accuracy, robust | Slow, black-box | General purpose |
| **Gradient Boosting** | Both | Best accuracy | Very slow, overfits | Competitions, critical tasks |
| **SVM** | Both | Works in high-dim | Slow, needs scaling | Small-medium datasets |
| **k-NN** | Both | Simple, non-parametric | Slow prediction, needs scaling | Small datasets |
| **Naive Bayes** | Classification | Fast, works with small data | Strong independence assumption | Text classification |
| **Neural Network** | Both | Learns complex patterns | Needs lots of data, slow | Large datasets, images, text |
| **k-Means** | Clustering | Fast, simple | Needs k, sensitive to init | Spherical clusters |
| **DBSCAN** | Clustering | Finds any shape, detects outliers | Sensitive to params | Arbitrary-shaped clusters |
| **PCA** | Dim Reduction | Fast, interpretable | Linear only | Preprocessing, visualization |

---

## ğŸ”„ Train/Val/Test Split Strategy

```
Full Dataset (100%)
â”‚
â”œâ”€ Train Set (60-80%) â”€â”€â”€â”€â”€â”€â”€â”€â–º FIT models, transformers
â”‚
â”œâ”€ Validation Set (10-20%) â”€â”€â”€â–º TUNE hyperparameters, SELECT models
â”‚
â””â”€ Test Set (10-20%) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º EVALUATE final model (USE ONCE!)
```

**Golden Rules**:
1. **Split BEFORE any preprocessing**
2. **Fit transformers on train only**
3. **Never touch test set until final evaluation**
4. **Stratify for classification** (`stratify=y`)
5. **NO shuffling for time series!**

---

## ğŸ“ˆ Evaluation Metrics Quick Reference

### Classification

| Metric | Formula | When to Use | Range |
|--------|---------|-------------|-------|
| **Accuracy** | (TP+TN) / Total | Balanced classes | [0, 1] |
| **Precision** | TP / (TP+FP) | Minimize false positives | [0, 1] |
| **Recall** | TP / (TP+FN) | Minimize false negatives | [0, 1] |
| **F1-Score** | 2Â·(PÂ·R)/(P+R) | Imbalanced data | [0, 1] |
| **AUC-ROC** | Area under ROC curve | Overall performance | [0, 1] |

**Confusion Matrix**:
```
                Predicted
              Neg       Pos
Actual  Neg   TN        FP
        Pos   FN        TP
```

### Regression

| Metric | Formula | Interpretation | Range |
|--------|---------|----------------|-------|
| **MAE** | Mean(\|y-Å·\|) | Average error | [0, âˆ) |
| **MSE** | Mean((y-Å·)Â²) | Penalizes large errors | [0, âˆ) |
| **RMSE** | âˆšMSE | Same unit as target | [0, âˆ) |
| **RÂ²** | 1 - SS_res/SS_tot | Variance explained | (-âˆ, 1] |

---

## âš™ï¸ Hyperparameter Tuning Guide

### Key Hyperparameters by Model

**Decision Tree**:
- `max_depth`: 3-20 (prevent overfitting)
- `min_samples_split`: 2-20
- `min_samples_leaf`: 1-10

**Random Forest**:
- `n_estimators`: 100-1000 (more = better, slower)
- `max_depth`: 10-50
- `max_features`: 'sqrt' or 'log2'

**Gradient Boosting**:
- `n_estimators`: 100-1000
- `learning_rate`: 0.01-0.3 (lower = better but slower)
- `max_depth`: 3-10 (shallow trees!)

**SVM**:
- `C`: 0.1-100 (regularization, lower = more)
- `kernel`: 'linear', 'rbf', 'poly'
- `gamma`: 0.001-1 (for RBF)

**Neural Network**:
- `learning_rate`: 0.0001-0.1
- `batch_size`: 16-256
- `epochs`: 10-1000 (with early stopping)
- `dropout`: 0.2-0.5

---

## ğŸ› ï¸ Preprocessing Checklist

### Numerical Features
- [ ] **Handle missing values**: SimpleImputer (mean/median/mode)
- [ ] **Scale features**: StandardScaler or MinMaxScaler
- [ ] **Remove outliers**: IQR method or Isolation Forest
- [ ] **Create polynomial features**: PolynomialFeatures

### Categorical Features
- [ ] **Encode target**: LabelEncoder
- [ ] **Encode features**: OneHotEncoder (nominal) or OrdinalEncoder (ordinal)
- [ ] **Handle high cardinality**: Target encoding or frequency encoding

### Text Features
- [ ] **Tokenization**: CountVectorizer or TfidfVectorizer
- [ ] **Remove stop words**: English stopwords
- [ ] **Stemming/Lemmatization**: NLTK or spaCy
- [ ] **Embeddings**: Word2Vec, GloVe, BERT

### Feature Engineering
- [ ] **Domain-specific features**: Based on business logic
- [ ] **Interaction terms**: Feature1 Ã— Feature2
- [ ] **Binning**: Convert continuous to categorical
- [ ] **Date features**: Extract year, month, day, weekday

---

## ğŸ” Bias-Variance Tradeoff

```
    Error
      â†‘
      â”‚     â•±Total Error
      â”‚    â•±
      â”‚   â•±â•² 
      â”‚  â•±  â•²
      â”‚ â•±    â•²___Variance
      â”‚â•±      
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Model Complexity
     Bias
     
Underfitting â†â”€â”€â”€ Optimal â”€â”€â”€â†’ Overfitting
(High Bias)                   (High Variance)
```

**Signs of Overfitting**:
- Training accuracy >> Test accuracy
- Perfect training, poor test
- **Fix**: More data, regularization, simpler model, cross-validation

**Signs of Underfitting**:
- Low training AND test accuracy
- **Fix**: More features, complex model, less regularization

---

## ğŸš¨ Common ML Pitfalls

### Data Leakage
```python
# âŒ WRONG
X_scaled = scaler.fit_transform(X)
X_train, X_test = train_test_split(X_scaled)

# âœ“ CORRECT
X_train, X_test = train_test_split(X)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### Using Test Set for Tuning
```python
# âŒ WRONG: Tuning on test set
for param in params:
    model.fit(X_train, y_train)
    if model.score(X_test, y_test) > best:  # Leakage!
        best = model

# âœ“ CORRECT: Use validation/CV
grid_search = GridSearchCV(model, param_grid, cv=5)
grid_search.fit(X_train, y_train)
final_score = grid_search.score(X_test, y_test)  # ONE time!
```

### Not Scaling for Distance-Based Models
- **Must scale**: k-NN, SVM, Neural Networks, k-Means
- **No need**: Decision Trees, Random Forest, Naive Bayes

### Imbalanced Data Mistakes
- Using accuracy (use F1, precision/recall instead)
- Not stratifying train/test split
- Not using class weights or SMOTE

---

## ğŸ§® Key Formulas

### Scaling
```
StandardScaler: (x - Î¼) / Ïƒ
MinMaxScaler: (x - min) / (max - min)
```

### Regularization
```
Ridge (L2): Loss + Î»Â·Î£(Î²Â²)
Lasso (L1): Loss + Î»Â·Î£|Î²|
ElasticNet: Loss + Î»â‚Â·Î£|Î²| + Î»â‚‚Â·Î£(Î²Â²)
```

### Distance Metrics
```
Euclidean: âˆš[Î£(x-y)Â²]
Manhattan: Î£|x-y|
Cosine: (xÂ·y) / (||x||Â·||y||)
```

### Information Theory
```
Entropy: -Î£ p(x)Â·logâ‚‚(p(x))
Information Gain: Entropy(parent) - Weighted_Avg(Entropy(children))
Gini: 1 - Î£ pÂ²(x)
```

---

## ğŸ“š Scikit-Learn API Pattern

```python
# 1. Import
from sklearn.xxx import YourModel

# 2. Instantiate
model = YourModel(param1=value1, param2=value2)

# 3. Fit (train)
model.fit(X_train, y_train)

# 4. Predict
y_pred = model.predict(X_test)

# 5. Evaluate
score = model.score(X_test, y_test)

# Key attributes (after fitting):
model.coef_          # Coefficients (linear models)
model.feature_importances_  # Importance (tree models)
model.n_features_in_ # Number of features
```

---

## ğŸ¯ Quick Decision Guide

**Q: Small dataset (<1000 samples)?**
â†’ Use: Logistic Regression, Naive Bayes, SVM (avoid deep learning)

**Q: Need interpretability?**
â†’ Use: Linear Regression, Logistic Regression, Decision Tree

**Q: Have lots of data (>100K samples)?**
â†’ Use: Neural Networks, Gradient Boosting, Random Forest

**Q: High-dimensional data?**
â†’ Use: PCA for preprocessing, then any model

**Q: Imbalanced classes?**
â†’ Use: F1-score, SMOTE, class weights, stratified CV

**Q: Time series data?**
â†’ Use: ARIMA, LSTM, Prophet (NO random shuffling!)

**Q: Text data?**
â†’ Use: TF-IDF + Logistic Regression / Naive Bayes, or BERT

**Q: Image data?**
â†’ Use: CNN, Transfer Learning (ResNet, VGG), Vision Transformers

---

## ğŸ’¡ Exam Tips

### Must Remember
1. **Train/test must be split BEFORE preprocessing**
2. **Accuracy is BAD for imbalanced data**
3. **k-NN, SVM, Neural Nets NEED scaling**
4. **LabelEncoder for target, OneHotEncoder for features**
5. **Cross-validation for hyperparameter tuning, NOT test set**
6. **Stratify for classification, especially if imbalanced**
7. **NO shuffling for time series**
8. **Pipeline prevents data leakage**
9. **Regularization prevents overfitting (Î»â†‘ = regularizationâ†‘)**
10. **More trees in Random Forest = better (but slower)**

### Common MCQ Traps
- "Accuracy is best metric for all tasks" â†’ **FALSE** (imbalanced!)
- "Test set used for hyperparameter tuning" â†’ **FALSE** (validation!)
- "Scale before train/test split" â†’ **FALSE** (data leakage!)
- "Decision trees need feature scaling" â†’ **FALSE** (only distance-based!)
- "Overfitting means high train AND test error" â†’ **FALSE** (that's underfitting!)

---

**Print this page for quick exam reference!** ğŸ“„

**End of Cheat Sheet**
