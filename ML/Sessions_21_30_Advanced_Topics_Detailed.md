# Sessions 21-30 ‚Äì Modern AI & Advanced Topics (Detailed)

---

# Session 21 ‚Äì Modern Large Language Models

## üìö Core Concepts

### Scaling Laws
**Power law relationship**: Performance ‚àù N^Œ± (N = parameters, data, compute)

**Emergent abilities** appear at scale:
- Chain-of-thought reasoning
- Few-shot learning
- In-context learning

### Model Architectures

**GPT-3.5/4** (OpenAI):
- 175B+ parameters
- Instruction-tuned
- RLHF alignment

**LLaMA** (Meta):
- 7B to 70B parameters
- Open weights
- Efficient training

**Claude** (Anthropic):
- Constitutional AI
- Longer context (100K tokens)
- Helpfulness + harmlessness

**PaLM 2** (Google):
- Multilingual
- Improved reasoning
- Efficient compute

### Training Techniques

**Instruction Tuning**:
```
Input: "Summarize this article: [text]"
Output: [summary]
```

**RLHF** (Reinforcement Learning from Human Feedback):
1. Supervised fine-tuning
2. Reward model training
3. PPO optimization

**Constitutional AI**:
- Self-critique and revision
- Principle-based alignment

---

# Session 22 ‚Äì Advanced Computer Vision

## Object Detection

### R-CNN Family

**R-CNN**: Region proposals + CNN
**Fast R-CNN**: ROI pooling
**Faster R-CNN**: RPN (Region Proposal Network)

### YOLO (You Only Look Once)

**Single-stage detector**: Direct bounding box + class prediction

```
Grid cells ‚Üí Bounding boxes + Confidence + Class probabilities
```

**Versions**:
- YOLOv1-v3: Progressions
- YOLOv5: PyTorch, optimized
- YOLOv8: Latest, best accuracy

### SSD (Single Shot Detector)

Multiple feature maps at different scales.

## Image Segmentation

### Semantic Segmentation
Pixel-wise classification (all pixels of class labeled same).

### Instance Segmentation
Individual object instances.

**Mask R-CNN**: Faster R-CNN + segmentation branch

### U-Net Architecture
```
Encoder (downsampling) ‚Üí Bottleneck ‚Üí Decoder (upsampling)
Skip connections between corresponding encoder-decoder levels
```

**Applications**: Medical imaging, satellite imagery

---

# Session 23 ‚Äì Generative Adversarial Networks

## üßÆ GAN Framework

**Min-max game**:
```
min_G max_D V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]
```

**Generator G**: Noise z ‚Üí Fake sample G(z)
**Discriminator D**: Real/Fake classifier

### Training Algorithm
```
1. Train D: Maximize log D(x) + log(1 - D(G(z)))
2. Train G: Maximize log D(G(z))  [or minimize log(1 - D(G(z)))]
Alternate until convergence
```

### Challenges
- **Mode collapse**: G produces limited variety
- **Training instability**: Oscillation, non-convergence
- **Vanishing gradients**: D too strong ‚Üí G can't learn

### Variants

**DCGAN**: Deep Convolutional GAN
- BatchNorm, LeakyReLU
- Strided convolutions (no pooling)

**StyleGAN**: 
- Style-based generator
- High-quality face generation
- Latent space manipulation

**CycleGAN**:
- Unpaired image-to-image translation
- Cycle consistency loss

**Conditional GAN**:
- Condition on class label
- Controlled generation

---

# Session 24 ‚Äì Variational Autoencoders & Diffusion Models

## VAE (Variational Autoencoder)

### Architecture
```
Input ‚Üí Encoder ‚Üí Œº, œÉ¬≤ ‚Üí Sample z ~ N(Œº, œÉ¬≤) ‚Üí Decoder ‚Üí Output
```

**Loss**:
```
L = Reconstruction_loss + KL_divergence(q(z|x) || p(z))
```

**Reparameterization trick**:
```
z = Œº + œÉ ‚äô Œµ where Œµ ~ N(0, I)
```

Allows backpropagation through sampling.

## Diffusion Models

### Forward Process (Add noise)
```
q(x_t | x_{t-1}) = N(x_t; ‚àö(1-Œ≤_t) x_{t-1}, Œ≤_t I)
```

Gradually add Gaussian noise over T steps.

### Reverse Process (Denoise)
```
p_Œ∏(x_{t-1} | x_t) = N(x_{t-1}; Œº_Œ∏(x_t, t), Œ£_Œ∏(x_t, t))
```

Learn to reverse the noise process.

### Training
Predict noise added at each step:
```
L = E[||Œµ - Œµ_Œ∏(x_t, t)||¬≤]
```

### Stable Diffusion
- Latent diffusion (work in latent space)
- Text conditioning via CLIP
- Efficient generation

---

# Session 25 ‚Äì Advanced NLP Topics

## Word Embeddings

### Word2Vec
**CBOW**: Context ‚Üí Word
**Skip-gram**: Word ‚Üí Context

Loss: Negative sampling

### GloVe
Matrix factorization on co-occurrence statistics.

### Contextual Embeddings
**ELMo**: Bidirectional LSTM
**BERT embeddings**: Layer outputs as features

## Seq2Seq Models

### Encoder-Decoder
```
Encoder: Input sequence ‚Üí Context vector
Decoder: Context vector ‚Üí Output sequence
```

**With attention**:
- Dynamic context at each decoder step
- Alignment between input/output

### Applications
- Machine translation
- Summarization
- Dialogue systems

---

# Session 26 ‚Äì Reinforcement Learning

## Core Concepts

**MDP** (Markov Decision Process):
- States S
- Actions A  
- Transition P(s'|s,a)
- Reward R(s,a)
- Discount Œ≥

**Goal**: Learn policy œÄ(a|s) maximizing expected return.

### Value Functions
```
V^œÄ(s) = E[Œ£ Œ≥^t r_t | s_0=s, œÄ]  (state value)
Q^œÄ(s,a) = E[Œ£ Œ≥^t r_t | s_0=s, a_0=a, œÄ]  (action value)
```

### Bellman Equations
```
V(s) = Œ£_a œÄ(a|s) Œ£_{s'} P(s'|s,a)[R(s,a) + Œ≥V(s')]
Q(s,a) = Œ£_{s'} P(s'|s,a)[R(s,a) + Œ≥ Œ£_{a'} œÄ(a'|s')Q(s',a')]
```

## Algorithms

### Q-Learning (Off-policy TD)
```
Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥ max_a' Q(s',a') - Q(s,a)]
```

### SARSA (On-policy TD)
```
Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥Q(s',a') - Q(s,a)]
```

### Policy Gradient (REINFORCE)
```
‚àáJ(Œ∏) = E[‚àálog œÄ_Œ∏(a|s) R]
```

### Actor-Critic
Combine value function (critic) and policy (actor).

---

# Session 27 ‚Äì Deep Reinforcement Learning

## DQN (Deep Q-Network)

**Innovations**:
1. **Experience replay**: Store transitions, sample mini-batches
2. **Target network**: Stabilize Q-learning

```python
# Q-update with target network
Q_target = r + Œ≥ max_a Q_target(s', a)
Loss = (Q(s,a) - Q_target)¬≤
```

## Advanced Algorithms

### A3C (Asynchronous Advantage Actor-Critic)
Multiple parallel agents, shared network.

### PPO (Proximal Policy Optimization)
```
Clip objective: min(r_t(Œ∏)A_t, clip(r_t(Œ∏), 1-Œµ, 1+Œµ)A_t)
```

Prevents large policy updates.

### TRPO (Trust Region Policy Optimization)
Constrained optimization:
```
max E[...] subject to KL(œÄ_old || œÄ_new) ‚â§ Œ¥
```

## Applications
- Game playing (AlphaGo, Dota 2)
- Robotics
- Recommendation systems
- Resource allocation

---

# Session 28 ‚Äì MLOps & Production ML

## Model Deployment

### REST API
```python
from fastapi import FastAPI
import torch

app = FastAPI()
model = torch.load('model.pth')

@app.post("/predict")
def predict(data: dict):
    input_tensor = preprocess(data)
    output = model(input_tensor)
    return {"prediction": postprocess(output)}
```

### Docker Containerization
```dockerfile
FROM python:3.9
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY model.pth app.py .
CMD ["uvicorn", "app:app", "--host", "0.0.0.0"]
```

### Model Serving
- **TensorFlow Serving**: Optimized for TF models
- **TorchServe**: PyTorch models
- **ONNX Runtime**: Cross-framework

## Monitoring

### Metrics to Track
- **Performance**: Latency, throughput
- **Accuracy**: Online metrics
- **Data drift**: Input distribution changes
- **Model drift**: Performance degradation

### A/B Testing
```
Traffic split: 90% model A, 10% model B
Compare: accuracy, latency, business metrics
Gradual rollout if B better
```

## ML Pipelines

### Kubeflow
Kubernetes-based ML workflows

### MLflow
- Experiment tracking
- Model registry
- Deployment

### DVC (Data Version Control)
Version datasets + models with Git-like interface

---

# Session 29 ‚Äì AI Ethics & Fairness

## Bias & Fairness

### Sources of Bias
1. **Historical bias**: Data reflects societal biases
2. **Representation bias**: Some groups underrepresented
3. **Measurement bias**: Proxies for protected attributes
4. **Aggregation bias**: One model for diverse groups

### Fairness Metrics

**Demographic Parity**:
```
P(≈∂=1 | A=0) = P(≈∂=1 | A=1)
```

**Equal Opportunity**:
```
P(≈∂=1 | Y=1, A=0) = P(≈∂=1 | Y=1, A=1)  (TPR equality)
```

**Equalized Odds**:
```
TPR and FPR equal across groups
```

### Mitigation Strategies
- **Pre-processing**: Re-sample, re-weight training data
- **In-processing**: Fairness constraints during training
- **Post-processing**: Adjust predictions for fairness

## Explainability

### LIME (Local Interpretable Model-agnostic Explanations)
Approximate model locally with interpretable model.

### SHAP (SHapley Additive exPlanations)
Game-theoretic feature attribution:
```
œÜ_i = Œ£ [v(S‚à™{i}) - v(S)] / (combinations)
```

### Attention Visualization
Show which inputs model focuses on.

## Privacy

### Differential Privacy
Add calibrated noise to preserve privacy:
```
P(M(D) ‚àà S) ‚â§ e^Œµ P(M(D') ‚àà S)
```

### Federated Learning
Train on decentralized data without sharing.

---

# Session 30 ‚Äì Future of AI & Emerging Trends

## Multimodal Learning

### CLIP (Contrastive Language-Image Pre-training)
Learn joint text-image embeddings:
```
Maximize: similarity(image_i, caption_i)
Minimize: similarity(image_i, caption_j) for i‚â†j
```

**Applications**: Zero-shot classification, image search

### Flamingo
Few-shot vision-language model.

## Efficient AI

### Model Compression

**Pruning**: Remove unimportant weights
**Quantization**: Use lower precision (INT8 vs FP32)
**Knowledge Distillation**: Train small model to mimic large model

```
L = L_task + Œ± KL(p_student || p_teacher)
```

### Neural Architecture Search
Automated model design.

## Retrieval-Augmented Generation (RAG)

```
Query ‚Üí Retrieve relevant docs ‚Üí LLM with context ‚Üí Response
```

Grounds generation in external knowledge.

## AI Agents

**AutoGPT**: Autonomous task completion
**LangChain**: Framework for LLM applications
**Function calling**: LLMs use external tools

## Constitutional AI
Models critique and revise own outputs based on principles.

## Industry Impact

**Healthcare**: Drug discovery, diagnosis
**Finance**: Fraud detection, algorithmic trading  
**Climate**: Weather prediction, optimization
**Science**: Protein folding (AlphaFold), materials discovery

---

**üéâ ALL 30 SESSIONS NOW FULLY DETAILED! üéâ**
